{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Individual remote sensing images can be affected by noisy data, including clouds, cloud shadows, and haze. \n",
    "To produce cleaner images that can be compared more easily across time, we can create 'summary' images or 'composites' that combine multiple images into one by reducing dimensions.\n",
    "\n",
    "Some methods for generating composites include estimating the `median`, `mean`, `minimum`, or `maximum` pixel values in an image.\n",
    "Care must be taken with these, as they do not necessarily preserve spectral relationships across bands. \n",
    "To learn how to generate a composite that does preserve these relationships, see the [Generating geomedian composites notebook](Generating_geomedian_composites.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook demonstrates how to generate a number of different composites from satellite images, and discusses the uses of each.\n",
    "Specifically, this notebook demonstrates how to generate:\n",
    "\n",
    "1. Median composites\n",
    "2. Mean composites\n",
    "3. Minimum and maximum composites\n",
    "4. Nearest-time composites\n",
    "5. Perform a PCA\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from dea_tools.datahandling import load_ard, first, last, nearest\n",
    "from dea_tools.bandindices import calculate_indices#\n",
    "from dea_tools.plotting import rgb\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import odc.stac\n",
    "from pystac.extensions.eo import EOExtension as eo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install dea-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Landsat 8 data\n",
    "\n",
    "Here we load a timeseries of cloud-masked Landsat 8 satellite images through the datacube API using the [load_ard](Using_load_ard.ipynb) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "bbox_of_interest = [9.9805, 49.8597, 10.1261, 49.9556]\n",
    "time_of_interest = \"2021-01-01/2021-12-31\"\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=[\"landsat-c2-l2\"],\n",
    "    bbox=bbox_of_interest,\n",
    "    datetime=time_of_interest,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 10}, # filtering with cloud limit 10 %\n",
    "          \"platform\": {\"in\": [\"landsat-8\"]}} # here we filter Landsat 8 tiles\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "print(f\"Returned {len(items)} Items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = odc.stac.stac_load(items, \n",
    "                          bands=[\"green\",\"red\",\"blue\",\"nir08\",\"qa_pixel\"], \n",
    "                          bbox=bbox_of_interest,\n",
    "                          #chunks={},\n",
    "                          groupby=\"solar_day\")#.isel(time=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud masking\n",
    "Here we utilize the `qa_pixel` band with the binary coded quality flags. [Humboldt Univerity of Berlin](https://pages.cms.hu-berlin.de/EOL/gcg_eo/02_data_quality.html) gives further information on using the quality flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used qa values\n",
    "mask_val = [21762, 21890, 21952, 22018, 22080, 22280, 23826, 23888, 24082, 24144, 55052]\n",
    "# write maseed dataset `data_clean`\n",
    "data_clean = data.where(data.qa_pixel.isin(mask_val) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For decoding decimal values you can use this function\n",
    "def dec_to_bin(x):\n",
    "    return int(bin(x)[2:])\n",
    "\n",
    "for i in mask_val:\n",
    "    print(dec_to_bin(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot timesteps in true colour\n",
    "\n",
    "To visualise the data, use the pre-loaded `rgb` utility function to plot a true colour image for a series of timesteps. \n",
    "White areas indicate where clouds or other invalid pixels in the image have been masked.\n",
    "\n",
    "The code below will plot three timesteps of the time series we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timesteps to visualise\n",
    "timesteps =  [2, 3, 5]\n",
    "\n",
    "# Generate RGB plots at each timestep\n",
    "# For the rgb image a stretch all pixel values are used,i.e.\n",
    "# if you load cloudy and non cloudy images together, it can\n",
    "# be useful to use \"percentile_stretch\" attribute to cut\n",
    "# extreme values for visualization purposes\n",
    "rgb(data_clean, \n",
    "    index=timesteps, \n",
    "    bands=['red', 'green','blue'], \n",
    "    #percentile_stretch=(0.1,0.99) \n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with not masked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timesteps to visualise\n",
    "timesteps =  [2, 3, 5]\n",
    "\n",
    "rgb(data, \n",
    "    index=timesteps, \n",
    "    bands=['red', 'green','blue'], \n",
    "    #percentile_stretch=(0.1,0.99) \n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median composites\n",
    "\n",
    "One of the key reasons for generating a composite is to replace pixels classified as clouds with realistic values from the available data. \n",
    "This results in an image that doesn't contain any clouds.\n",
    "In the case of a median composite, each pixel is selected to have the median (or middle) value out of all possible values.\n",
    "\n",
    "Care should be taken when using these composites for analysis, since the relationships between spectral bands are not preserved.\n",
    "These composites are also affected by the timespan they're generated over.\n",
    "For example, the median pixel in a single season may be different to the median value for the whole year.\n",
    "\n",
    "> **Note:** For an advanced compositing method that maintains spectral relationships between satellite bands, refer to the [Generating geometric median composites](./Generating_geomedian_composites.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a single median composite from all data\n",
    "\n",
    "To generate a single median composite, we use the `xarray.median` method, specifying `'time'` as the dimension to compute the median over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a single median from all data\n",
    "ds_median = data_clean.median('time') # you can change to \"data.median('time')\" to build a non cloud masked image\n",
    "\n",
    "# View the resulting median\n",
    "rgb(ds_median, \n",
    "    bands=['red', 'green', 'blue'],\n",
    "    #percentile_stretch=(0.0001,0.9999)\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize different composites, e.g. standard deviation to show the spectral variabiltiy in different measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a single standard deviation from all data\n",
    "ds_std = data_clean.std('time') # you can change to \"data.median('time')\" to build a non cloud masked image\n",
    "\n",
    "# View the resulting median\n",
    "rgb(ds_std, \n",
    "    bands=['red', 'green', 'blue'],\n",
    "    #percentile_stretch=(0.0001,0.9999)\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating multiple median composites based on length of time\n",
    "Rather than using all the data to generate a single median composite, it's possible to use the `xarray.resample` method to group the data into smaller time-spans and generate medians for each of these.\n",
    "Some resampling options are\n",
    "* `'nD'` - number of days (e.g. `'7D'` for seven days)\n",
    "* `'nM'` - number of months (e.g. `'6M'` for six months)\n",
    "* `'nY'` - number of years (e.g. `'2Y'` for two years)\n",
    "\n",
    "If the area is particularly cloudy during one of the time-spans, there may still be masked pixels that appear in the median.\n",
    "This will be true if that pixel is always masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a median by binning data into six-monthly time-spans\n",
    "ds_resampled_median = data_clean.resample(time='6M').median('time')\n",
    "\n",
    "# View the resulting medians\n",
    "rgb(ds_resampled_median, index=[1, 2], bands=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By\n",
    "Similar to resample, grouping works by looking at part of the date, but ignoring other parts. For instance, `'time.month'` would group together all January data together, no matter what year it is from.\n",
    "\n",
    "Some examples are:\n",
    " * `'time.day'` - groups by the day of the month (1-31)\n",
    " * `'time.dayofyear'` - groups by the day of the year (1-365)\n",
    " * `'time.week'` - groups by week (1-52) \n",
    " * `'time.month'` - groups by the month (1-12)\n",
    " * `'time.season'` - groups into 3-month seasons:\n",
    "     - `'DJF'` December, Jaunary, February\n",
    "     - `'MAM'` March, April, May\n",
    "     - `'JJA'` June, July, August\n",
    "     - `'SON'` September, October, November\n",
    " * `'time.year'` - groups by the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a median by binning data into six-monthly time-spans\n",
    "ds_groupby_season = data_clean.groupby('time.season').median()\n",
    "\n",
    "# View the resulting medians\n",
    "rgb(ds_groupby_season, col='season', bands=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean composites\n",
    "\n",
    "Mean composites involve taking the average value for each pixel, rather than the middle value as is done for a median composite.\n",
    "Unlike the median, the mean composite can contain pixel values that were not part of the original dataset.\n",
    "Care should be taken when interpreting these images, as extreme values (such as unmasked cloud) can strongly affect the mean.\n",
    "\n",
    "### Generating a single mean composite from all data\n",
    "\n",
    "To generate a single mean composite, we use the `xarray.mean` method, specifying `'time'` as the dimension to compute the mean over.\n",
    "\n",
    "> **Note**: If there are no valid values for a given pixel, you may see the warning:\n",
    "`RuntimeWarning: Mean of empty slice`. The composite will still be generated, but may have blank areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a single mean from all data\n",
    "ds_mean = data_clean.mean('time')\n",
    "\n",
    "# View the resulting mean\n",
    "rgb(ds_mean, bands=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating multiple mean composites based on a length of time\n",
    "As with the median composite, it's possible to use the `xarray.resample` method to group the data into smaller time-spans and generate means for each of these.\n",
    "See the previous section for some example resampling time-spans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you get the warning `RuntimeWarning: Mean of empty slice`, this just means that for one of your groups there was at least one pixel that contained all `nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mean by binning data into six-monthly time-spans\n",
    "ds_resampled_mean = data_clean.resample(time='6M').mean('time')\n",
    "\n",
    "# View the resulting medians\n",
    "rgb(ds_resampled_mean, index=[1,2], bands=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum and maximum composites\n",
    "\n",
    "These composites can be useful for identifying extreme behaviour in a collection of satellite images.\n",
    "\n",
    "For example, comparing the maximum and minimum composites for a given band index could help identify areas that take on a wide range of values, which may indicate areas that have high variability over the time-line of the composite.\n",
    "\n",
    "To demonstrate this, we start by calculating the normalised difference vegetation index (NDVI) for our data, which can then be used to generate the maximum and minimum composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by calculating NDVI\n",
    "data[\"ndvi\"] = (data.nir08-data.red)/(data.nir08+data.red)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum composite\n",
    "\n",
    "To generate a single maximum composite, we use the `xarray.max` method, specifying `'time'` as the dimension to compute the maximum over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the maximum composite\n",
    "# with high cloud laod this will cause runtime warnings\n",
    "da_max = data.ndvi.max('time')\n",
    "\n",
    "# View the resulting composite\n",
    "da_max.plot(vmin=-1, vmax=0.7, cmap='RdYlGn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum composite\n",
    "\n",
    "To generate a single minimum composite, we use the `xarray.min` method, specifying `'time'` as the dimension to compute the minimum over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the minimum composite\n",
    "da_min = data.ndvi.min('time')\n",
    "\n",
    "# View the resulting composite\n",
    "da_min.plot(vmin=-0.5, vmax=0.2, cmap='RdYlGn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest-time composites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an image at a certain time, often there is missing data, due to clouds and other masking.  We can fill in these gaps by using data from surrounding times.\n",
    "\n",
    "To generate these images, we can use the custom functions `first`, `last` and `nearest` from the [dea_datahandling](../Scripts/dea_datahandling.py#716) script.\n",
    "\n",
    "You can also use the in-built `.first()` and `.last()` methods when doing `groupby` and `resample` as described above. They are described in the [xarray documentation](http://xarray.pydata.org/en/stable/groupby.html#first-and-last) on grouped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most-recent composite\n",
    "\n",
    "Sometime we may want to determine what the landscape looks like by examining the most recent image.  If we look at the last image for our dataset, we can see there is lots of missing data in the last image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the last image in time\n",
    "rgb(data_clean, index=-1, bands=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate how much of the data is missing in this most recent image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_blue_image = data_clean.blue.isel(time=-1)\n",
    "\n",
    "precent_valid_data = float(last_blue_image.count() / \n",
    "                           last_blue_image.size) * 100\n",
    "print(f'The last image contains {precent_valid_data:.2f}% data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fill in the gaps and produce a complete image showing the most-recent satellite acquistion for every pixel, we can run the `last` function on one of the arrays.\n",
    "This will return the most recent cloud-free value that was observed by the satellite for every pixel in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_blue = last(data_clean.blue, dim='time') # wont work with dask chunks\n",
    "last_blue.plot(robust=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how recent each pixel is, we can compare the age of the pixels with the latest value we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify latest time in our data\n",
    "last_time = last_blue.time.max()\n",
    "\n",
    "# Compare the timestamps and convert them to number of days for plotting.\n",
    "num_days_old = (last_time - last_blue.time).dt.days\n",
    "num_days_old.plot(cmap='plasma', size=6);\n",
    "\n",
    "# yes, 70 days "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this method on all of the bands. \n",
    "However we only want pixels that have data in every band. \n",
    "On the edges of a satellite pass, some bands don't have data.\n",
    "\n",
    "To get rid of pixels with missing data, we will convert the dataset to an array, and select only those pixels with data in all bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to array\n",
    "da = data_clean.to_array(dim='variable')\n",
    "\n",
    "# Create a mask where data has no-data\n",
    "no_data_mask = da.isnull().any(dim='variable')\n",
    "\n",
    "# Mask out regions where there is no-data\n",
    "da = da.where(~no_data_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the `last` function on the array, then turn it back into a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_latest = last(da, dim='time')\n",
    "\n",
    "ds_latest = da_latest.to_dataset(dim='variable').drop_dims('variable')\n",
    "\n",
    "# View the resulting composite\n",
    "rgb(ds_latest, bands=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before and after composites\n",
    "\n",
    "Often it is useful to view images before and after an event, to see the change that has occured.\n",
    "\n",
    "To generate a composite on either side of an event, we can split the dataset along time.\n",
    "\n",
    "We can then view the composite `last` image before the event, and the composite `first` image after the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates here are inclusive. Use None to not set a start or end of the range.\n",
    "event_time = '2021-06-01'\n",
    "before_event = slice(None, event_time)\n",
    "after_event = slice(event_time, None)\n",
    "\n",
    "# Select the time period and run the last() or first() function on every band.\n",
    "da_before = last(da.sel(time=before_event), dim='time')\n",
    "da_after = first(da.sel(time=after_event), dim='time')\n",
    "\n",
    "# Convert both DataArrays back to Datasets for plotting\n",
    "ds_before = da_before.to_dataset(dim='variable').drop_dims('variable')\n",
    "ds_after = da_after.to_dataset(dim='variable').drop_dims('variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The composite image before the event, up to `2021-06-01`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ds_before,['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The composite image after the event, from `2020-06-01` onward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ds_after,['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest time composite\n",
    "\n",
    "Sometimes we just want the closest available data to a particular point in time. \n",
    "This composite will take values from before _or_ after the specified time to find the nearest observation to our target time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate nearest time composite\n",
    "da_nearest = nearest(da, dim='time', target=event_time)\n",
    "\n",
    "# Plot nearest time composite\n",
    "ds_nearest = da_nearest.to_dataset(dim='variable').drop_dims('variable')\n",
    "rgb(ds_nearest,['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the `time` for each pixel, we can see if the pixel was taken from before or after the target time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_datetime = da_nearest.time.dtype.type(event_time)\n",
    "\n",
    "# Calculate different in times and convert to number of days\n",
    "num_days_different = (da_nearest.time.min(dim='variable') - target_datetime).dt.days\n",
    "\n",
    "# Plot days before or after target date\n",
    "num_days_different.plot(cmap='bwr', levels=11, figsize=(6, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing spectral dimensions with PCA\n",
    "\n",
    "Principal Component Analysis (PCA) is a popular technique for dimensionality reduction. It can be used to explore patterns in high-dimensional data and assist unsupervised learning.\n",
    "\n",
    "Principal components are a series of linear combinations of the original variables, among which the first principal component accounts for the greatest variance within a dataset. Each subsequent principal component accounts for the next greatest possible variance and is uncorrelated with the previously defined components.\n",
    "\n",
    "This technique is useful also very for understanding Sentinel-2 data as images are captured in 12 spectral bands but only 3 variables can be visualized in a RGB composite. PCA can also be applied to timeseries data to investigate temporal evolution patterns for different land cover types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../Tools/')\n",
    "from dea_tools.datahandling import load_ard\n",
    "from dea_tools.plotting import rgb\n",
    "from dea_tools.classification import sklearn_flatten, sklearn_unflatten\n",
    "# package installing using\n",
    "# !pip install <PACKAGE01> <PACKAGE02>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and mask clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = odc.stac.stac_load(items, \n",
    "                          bands=[\"green\",\"red\",\"blue\",\"nir08\",\n",
    "                                 \"swir16\",\"swir22\",\"qa_pixel\"], \n",
    "                          bbox=bbox_of_interest,\n",
    "                          #chunks={},\n",
    "                          groupby=\"solar_day\")#.isel(time=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.where(data.qa_pixel.isin(mask_val) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data using selected input spectral bands\n",
    "rgb(data_clean,\n",
    "    bands=['swir22', 'nir08', 'blue'],\n",
    "    col='time',\n",
    "    col_wrap=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA to transform and visualize data\n",
    "To perform a PCA, data is first transformed into a numpy array that can be used by sklearn using the DEA function sklearn_flatten.\n",
    "We drop `qa_pixel` since it is not directly carrying spectral information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_clean.drop(['qa_pixel'])\n",
    "x = sklearn_flatten(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PCA model is generated with 3 principal components and fitted on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate how much variance is accounted for in each principal component. In the default example, the first principal component accounts for a much high variance than the next two.\n",
    "\n",
    "This step can help determine whether more principal components are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative variance in principal components:',\n",
    "      pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data can now be transformed into this new reference space and rearranged into an `xarray.Dataset` compatible with our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pca.transform(x)\n",
    "out = sklearn_unflatten(predict, data_clean)\n",
    "out = out.to_dataset(dim=out.dims[0]).transpose('time', 'y', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot single principal components by renaming the bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['pca1'] = out[0]\n",
    "out['pca2'] = out[1]\n",
    "out['pca2'] = out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.pca1.isel(time=2).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize PCA results as rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA bands\n",
    "rgb(out,\n",
    "    bands=[1, 0, 2],\n",
    "    col='time',\n",
    "    col_wrap=3,\n",
    "    percentile_stretch=[0.2, 0.90])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "\n",
    "**Last modified:** June 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
